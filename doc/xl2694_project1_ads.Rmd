---
title: "xiaoyi"
author: "Xiaoyi li"
date: "9/16/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Here we get a database called HappyDB that "a corpus of 100,000 crowd-sourced happy moments". We know many thing can make people smile. In this project we merged HappyDB and demographic.csv that contains demographic information of the workers who contributed to the happy moment collection to analyze the differences of happy moments by gender,country and age.I used word cloud, sentiment analysis and topic model to analysis the database and visualization the data.


Step 0: Check and install needed packages. Load the libraries and functions

```{r}
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(dplyr)
library(stringr)
library(tidyr)
library(janeaustenr)
library(ggplot2)
library(wordcloud)
library(stm)
library(quanteda)
library(reshape2)
library(plotly)
```

### Step 1: Data harvest

import the HappyDB from the website and then clean the text 

```{r}
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/cleaned_hm.csv'
hm_data <- read_csv(urlfile)

corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
  tm_map(content_transformer(tolower))%>%
  tm_map(removePunctuation)%>%
  tm_map(removeNumbers)%>%
  tm_map(removeWords, character(0))%>%
  tm_map(stripWhitespace)
```


Next we stem the words and convert them to a "tidy" object. We build a new dataframe called new_df that only contains the hmid,wid and text sentence and then count the number of comments made by each worker(the reason why we do this is we want to count the ratio of each word later.).Then add this column to new_df
```{r stemming}
stemmed <- tm_map(corpus, stemDocument) %>%
  tidy() %>%
  select(text)
new_df <- data_frame(hm_data$hmid, hm_data$wid, stemmed$text)
colnames(new_df) <- c('hmid', 'wid', 'text')

comment_count <- new_df %>% group_by(wid) %>% summarise(comment_num = n())
new_df <- merge(new_df, comment_count, by = 'wid')

```

Then splite each sentence into word and We remove stopwords provided by the "tidytext" package and add some custom stopword
```{r stopwords}
dict <- tidy(corpus) %>%
  select(text) %>%
  unnest_tokens(dictionary, text)

data("stop_words")
word <- c("happy","ago","yesterday","lot","today","months","month",
                 "happier","happiest","last","week","past")

stop_words <- stop_words %>%
  bind_rows(mutate(tibble(word), lexicon = "updated"))
```

Lastly, we complete the stems by picking the corresponding word with the highest frequency.
```{r tidy stems with dictionary}
completed <- new_df %>%
  unnest_tokens(stems, text) %>%
  bind_cols(dict) %>%
  anti_join(stop_words, by = c("dictionary" = "word"))

completed <- completed %>%
  group_by(stems) %>%
  count(dictionary) %>%
  mutate(word = dictionary[which.max(n)]) %>%
  ungroup() %>%
  select(stems, word) %>%
  distinct() %>%
  right_join(completed) %>%
  select(-stems)
```


because we want to do furture investigation then we import demographic.csv,including country,gender,age from the same databasethat.
For the ease of our further investigation, we combine file completed and demo.list together into one single file.
```{r}
demo <- read_csv('https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv')
merge_df <- merge(completed, demo, by = 'wid')
```

### step 2: sentiments analysis and data visualization

## step2.1  select words using sentiment lexicons "bing"

There are many sentiment lexicons available on the internet. So first Let's look at the words with a joy score from the bing lexicon. What are the most common positive and negative words inner join with our database? We can use wordcloud to plot it. From the result we can see "favorite","nice","won","beautiful","amazing","enjoyed","excited","awesome","bonus","free" are the top 10 positive words that mention mostly by by the people. Combined with my personal experience I will also feel happily like when I get my "favorite" gift, when I "enjoyed" a "exciting" films, when I get a "free meal"" and so on. 
```{r}
bing <- get_sentiments("bing")


j_word <- merge_df %>%
  inner_join(bing) %>%
  count(word, sentiment, sort = TRUE)


j_wid_word <- merge_df %>%
  inner_join(bing) %>%
  group_by(wid, word, sentiment) %>%
  summarise(count = n())

j_wid_word_final <- merge(j_wid_word, comment_count, by = 'wid')

j_wid_word_final$ratio <- j_wid_word_final$count / j_wid_word_final$comment_num

library(wordcloud)
library(reshape2)
j_word %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("#458B74", "#FF7F50"),
                   title.size=1.5, max.words = 150)

```

I also plot top10 positive words and top10 negative words. These histograms are more straghtforward to see words.
```{r}
j_word %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip() + theme_minimal(base_size = 7)
```


step2.2 analyze the frequency of the topten words mention by different age level

further more I am curious whether I could analyze the frequency of the topten words mention by different age group. Maybe the results will reflect the living habits of differnet age group.So I draw two graphs to show the results.The first one is the age for every year and the second one I classify the age [17,90] into 8 levels. From the first one we can see straighforward results in every age. The second one is very easy to compare young,middle and old age.

```{r}

merge_df$age <- as.numeric(merge_df$age)
age_count <- merge_df %>% group_by(age) %>%
  summarise(count = n()) %>% filter(age >= 5) %>% filter(age <= 200)




j_age_word <- merge_df %>%
  inner_join(bing) %>%
  group_by(age, word, sentiment) %>%
  summarise(count = n())

j_age_word_final <- merge(j_age_word, age_count, by = 'age')

j_age_word_final$ratio <- j_age_word_final$count.x / j_age_word_final$count.y
```

```{r}
pos = c("favorite","nice","won","beautiful","amazing","enjoyed","excited","awesome","bonus","free")
neg = c("bad","break","anxiety","difficult","lost","aggression","cold","hard","afraid","broke")
j_age_word_final_topten_pos <- j_age_word_final %>% filter(word %in% pos)
j_age_word_final_topten_neg <- j_age_word_final %>% filter(word %in% neg)

g2 <- ggplot(j_age_word_final_topten_pos, aes(age, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g2)


g3 <- ggplot(j_age_word_final_topten_neg, aes(age, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g3)
```

```{r}

library(Hmisc)
agebin <- cut2(age_count$age, cuts=c(30,40,50,60,70,80,90))
age_count$agebin <- agebin

agebin_count <- aggregate(age_count$count, by=list(Category=age_count$agebin), FUN=sum)


merge_df <- merge_df %>% filter(age >= 5 & age <= 200)
agebin2 <- cut2(merge_df$age, cuts=c(30,40,50,60,70,80,90))
merge_df$agebin <- agebin2

j_agebin_word <- merge_df %>%
  inner_join(bing) %>%
  group_by(agebin, word, sentiment) %>%
  summarise(count = n())

colnames(agebin_count) <- c("agebin","count")
j_agebin_word_final <- merge(j_agebin_word, agebin_count, by = 'agebin')

try <- data_frame(j_agebin_word_final$count.x)
try2 <- data_frame(j_agebin_word_final$count.y)
tryall <- cbind(try, try2)
colnames(tryall) <- c("try","try2")
tryall$ratio <- tryall$try /tryall$try2
j_agebin_word_final$ratio <- tryall$ratio
```

```{r}
pos = c("favorite","nice","won","beautiful","amazing","enjoyed","excited","awesome","bonus","free")
neg = c("bad","break","anxiety","difficult","lost","aggression","cold","hard","afraid","broke")
j_agebin_word_final_topten_pos <- j_agebin_word_final %>% filter(word %in% pos)
j_agebin_word_final_topten_neg <- j_agebin_word_final %>% filter(word %in% neg)
```


```{r}
g4 <- ggplot(j_agebin_word_final_topten_pos, aes(agebin, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g4)


g5 <- ggplot(j_agebin_word_final_topten_neg, aes(agebin, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g5)
```


From the result we see that "bonus" and "favorite" are more mentioned by people over 50 years old. And "won" are more mentioned by young people(except level [80,90]).It is make sense because young people like competiton and competiton actually exist in their life such as work and study. So when they won something they will feel so happy. For old people they usually buy clothing and others just follow their heart(buy their favority thing).They won't concern more about whether I can wear this to school or whether it is too expensive and so on.But old people consider more about "bonus". They work in a company for a long time, so they will put more attention on their bonus especially for people who will retire.


step2.2  analyze the frequency of the topten words mention by gender

Further more I am wondering whether I could analyze the frequency of the topten words mention by female and male. The results will reflect the living habits by gender. So I plot two graphs, the first one is positive words and second one is negative words.
```{r}
merge_df_gender <- merge(hm_data, demo, by = 'wid')

gender_count <- merge_df_gender %>% group_by(gender) %>% summarise(count = n())
g = c("f","m")
gender_count <- gender_count %>% filter(gender %in% g)


merge_df <- merge_df %>% filter(gender %in% g)
j_gender_word <- merge_df %>%
  inner_join(bing) %>%
  group_by(gender, word, sentiment) %>%
  summarise(count = n())

j_gender_word_final <- merge(j_gender_word, gender_count, by = 'gender')

j_gender_word_final$ratio <- j_gender_word_final$count.x / j_gender_word_final$count.y
```

```{r}
j_gender_word_final_topten_pos <- j_gender_word_final %>% filter(word %in% pos)
j_gender_word_final_topten_neg <- j_gender_word_final %>% filter(word %in% neg)


library(plotly)
g6 <- ggplot(j_gender_word_final_topten_pos, aes(gender, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g6)

g7 <- ggplot(j_gender_word_final_topten_neg, aes(gender, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g7)
```

From the graphs we can totally analysis the characters difference between female and male. On the view of male, they mention "amazing" and "aewsome" more frequently. This fits to male's characters. Male like to explore newness and mystery things, So "amazing"" and "aewsome"" things will make they more happy. But for female, they will buy their favority things instead of newness things. So women always buy the same brand's clothing and food. Also free things will make women more happily. 



step2.2  analyze the frequency of the topten words between parenthood

"most children report painful feelings about their parents' divorce, and a significant minority of children suffer extended and prolonged symptomatology related to parental divorce that may include both internalizing and externalizing problems" mentioned by Catherine M Lee in the paper "Children's reactions to parental separation and divorce". So this causes my curiosity, I want to use data to explore the emotion change. Are people whose parents are divorced more negative than people whose parents relationships are healthy?


```{r}
merge_df_parenthood <- merge(hm_data, demo, by = 'wid')

parenthood_count <- merge_df_parenthood %>% group_by(parenthood) %>% summarise(count = n()) %>% filter(count != 78)


j_parenthood_word <- merge_df %>%
  inner_join(bing) %>%
  group_by(parenthood, word, sentiment) %>%
  summarise(count = n()) 

j_parenthood_word_final <- merge(j_parenthood_word, parenthood_count, by = 'parenthood')

j_parenthood_word_final$ratio <- j_parenthood_word_final$count.x / j_parenthood_word_final$count.y
```

```{r}
j_parenthood_word_final_topten_pos <- j_parenthood_word_final %>% filter(word %in% pos)
j_parenthood_word_final_topten_neg <- j_parenthood_word_final %>% filter(word %in% neg)


g12 <- ggplot(j_parenthood_word_final_topten_pos, aes(parenthood, ratio,fill = word)) +
  geom_bar(stat = "identity", show.legend = FALSE)
ggplotly(g12)

```



People whose parenthood status are healthy mention more positive words than those whose parenthood status are broken. Because the number of people in level n and level y are differnt, So we use ratio= # of this words mention by people in this level/# of peopel in this level. This shows divorce have a influence to people.

Summary: We find many characters for differnt group people. Those findings give us many business value. For example, When we send email about our company's products, we can send more fancy styles to male and send more normal styles to women. For female we also can give some free gifts when they shopping at store. For older man we can give them more points that can redeem some thing when they shopping at our store. This is similar to "bonus". 





### step 3: Topic model
In this step, I want to apply some topic models. So first I delete all emotion words from the dataset. I want to put more attention on the events that make people happy.I also put age[17,90] into 8 levels. It is more convenience to compare with each other in this way. I want to explore what events make people happy in each age level.

```{r, echo=FALSE, fig.height=20, fig.width=20}
agebin <- cut2(age_count$age, cuts=c(30,40,50,60,70,80,90))
age_count$agebin <- agebin

agebin_count <- aggregate(age_count$count, by=list(Category=age_count$agebin), FUN=sum)


merge_df <- merge_df %>% filter(age >= 5 & age <= 200)
agebin2 <- cut2(merge_df$age, cuts=c(30,40,50,60,70,80,90))
merge_df$agebin <- agebin2

j_agebin_word <- merge_df %>%
  anti_join(bing) %>%
  group_by(agebin, word) %>%
  summarise(count = n())

colnames(agebin_count) <- c("agebin","count")
j_agebin_word_final <- merge(j_agebin_word, agebin_count, by = 'agebin')

try <- data_frame(j_agebin_word_final$count.x)
try2 <- data_frame(j_agebin_word_final$count.y)
tryall <- cbind(try, try2)
colnames(tryall) <- c("try","try2")
tryall$ratio <- tryall$try /tryall$try2
j_agebin_word_final$ratio <- tryall$ratio


j_agebin_word_final %>%
  bind_tf_idf(agebin,word,ratio) %>%
  group_by(agebin)%>%
  top_n(5)%>%
  ungroup%>%
  mutate(word=reorder(word,tf_idf))%>%
  ggplot(aes(word,tf_idf,fill=agebin))+
  geom_col(show.legend=FALSE)+
  facet_wrap(~agebin,scales="free_y")+
  coord_flip()
```

```{r}

sherlock_dfm<- j_agebin_word_final  %>%
  count(agebin,word,sort=TRUE) %>%
  cast_dfm(agebin,word,n) 
  

topic_model<-stm(sherlock_dfm,K=8,init.type="Spectral")
summary(topic_model)

```



